{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 21:03:36.831577: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-29 21:03:36.977286: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-29 21:03:37.084367: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-29 21:03:37.105396: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-29 21:03:37.203694: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-29 21:03:38.581486: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724987020.345259  410359 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1724987020.683728  410359 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1724987020.683825  410359 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "import splitfolders\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from art.estimators.classification import KerasClassifier\n",
    "from art.attacks.evasion import FastGradientMethod, CarliniLInfMethod, BasicIterativeMethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.__version__[0] != '2':\n",
    "    raise ImportError('This notebook requires TensorFlow v2.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = './dataset'\n",
    "data_dir = './dataset/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(data_dir, 'train') ## Train Dataset\n",
    "validation_dir = os.path.join(data_dir, 'val') ## Validation Dataset\n",
    "test_dir = os.path.join(data_dir, 'test') ## Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6300 images belonging to 2 classes.\n",
      "Found 1680 images belonging to 2 classes.\n",
      "Found 420 images belonging to 2 classes.\n",
      "Found 6300 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range = 20,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    fill_mode = 'nearest'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (150, 150),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size = (150, 150),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size = (150, 150),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "\n",
    "adversarial_generator = validation_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (150, 150),\n",
    "    batch_size = 10,\n",
    "    class_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'live': 0, 'spoof': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model accuracy on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1724987026.650130  410359 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1724987026.650264  410359 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1724987026.650282  410359 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1724987027.012577  410359 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1724987027.012640  410359 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-29 21:03:47.012650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1724987027.012693  410359 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-08-29 21:03:47.012987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3586 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('vgg19_msu_categorical.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724987027.941876  410525 service.cc:146] XLA service 0x7f7a10005060 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1724987027.941974  410525 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2024-08-29 21:03:47.962980: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-08-29 21:03:48.078605: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-08-29 21:03:48.293708: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_243', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 3/53\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0094"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1724987033.368306  410525 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 140ms/step - accuracy: 0.9986 - loss: 0.0106\n",
      "Evaluate compile_metrics: 99.82%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "scores = model.evaluate(validation_generator)\n",
    "print(\"%s%s: %.2f%%\" % (\"Evaluate \", model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a ART Keras classifier for the TensorFlow Keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "loss_object = CategoricalCrossentropy()\n",
    "\n",
    "classifier = TensorFlowV2Classifier(model=model,\n",
    "                                    clip_values=(0, 1), \n",
    "                                    nb_classes=2, \n",
    "                                    input_shape=(150, 150, 3), \n",
    "                                    loss_object=loss_object,\n",
    "                                    optimizer = tf.keras.optimizers.Adam(),\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,026</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m1,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv3 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv4 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv3 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv4 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv3 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv4 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │         \u001b[38;5;34m1,026\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,815,432</span> (79.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,815,432\u001b[0m (79.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">263,682</span> (1.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m263,682\u001b[0m (1.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,024,384</span> (76.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m20,024,384\u001b[0m (76.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">527,366</span> (2.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m527,366\u001b[0m (2.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Evaluate the classifier performance on the first 100 original test samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = next(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1724987046.566357  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987046.596991  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987046.610147  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987046.623691  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987046.636838  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987046.655813  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987046.668963  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987046.723927  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987046.740541  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987046.756905  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987046.776574  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987046.806553  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987046.819235  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987046.834477  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987046.856378  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987046.887536  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987046.907258  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987046.925225  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987046.955359  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987046.970963  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987046.978026  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987046.982015  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987046.986715  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987046.994451  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.001340  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.006055  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.012387  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.017661  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.022001  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.030387  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.039581  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.047101  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.052581  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.061226  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.067905  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.078310  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.165029  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.171583  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.177760  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.184258  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.195342  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.204846  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.211414  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.218194  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.228167  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.235153  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.245812  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.253195  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.259910  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.270677  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.277823  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.285784  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.294831  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.305904  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.317680  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.330361  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.342880  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.355490  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.365424  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.374805  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.385296  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.396451  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.406834  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.417545  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.429142  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.441656  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.453634  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.471141  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.481424  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.502365  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.524945  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.548305  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.574240  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987047.599788  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "2024-08-29 21:04:07.632133: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.38GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "W0000 00:00:1724987047.632455  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.215639  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.219174  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.222527  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.225730  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.229132  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.232271  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.235422  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.240829  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.244254  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.247364  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.250852  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.253938  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.257674  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.261190  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.265191  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.269087  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.273840  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.277993  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.282171  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.285882  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.290099  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.293986  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.298943  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.303675  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.309205  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.312984  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.317327  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.323457  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.328356  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.333268  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.338088  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.344609  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.350119  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.356909  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.362727  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.369061  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.375936  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.384294  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.416379  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.422040  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.427589  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.433241  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.438964  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.444906  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.450515  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.456506  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.462398  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.468340  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.475265  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.481367  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.487568  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.493899  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.499974  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.506249  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.512189  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.518248  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.524292  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.530494  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.538080  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.543924  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.551460  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.558518  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.566656  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.574591  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.582614  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.593760  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.604798  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.616424  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.627327  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.635364  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.648742  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.664457  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.679317  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.696792  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.724264  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "2024-08-29 21:04:08.753982: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.73GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "W0000 00:00:1724987048.783859  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.788609  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.792978  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.796362  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.800193  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.804144  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.807222  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.811163  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.814410  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.817681  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.820913  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.823715  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.826925  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.830140  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.833465  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.836711  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.840185  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.844758  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.847917  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.851082  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.854498  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.859186  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.863539  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.867252  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.871418  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.875473  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.879234  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.884022  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.888383  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.893105  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.899143  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.903811  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.909072  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.914082  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.919287  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.925554  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.930787  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.938094  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.965599  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.970724  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.975678  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.980433  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.985432  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.990655  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987048.995490  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.000456  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.005616  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.010758  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.015925  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.020869  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.026041  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.031204  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.036642  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.041886  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.046949  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.052395  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.057583  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.062849  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.067820  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.073382  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.079194  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.084587  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.091246  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.097157  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.102722  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.109238  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.115895  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.122363  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.130612  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.140881  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.151970  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.165225  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.174788  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.189395  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.220397  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.223861  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.226821  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.230382  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.233158  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.236988  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.240949  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.244078  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.247469  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.250175  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.253779  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.256645  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.259819  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.262569  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.265980  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.269532  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.272794  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.276610  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.279542  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.282892  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.285725  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.288938  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.291822  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.295760  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.299448  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.302507  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.306549  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.310347  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.317473  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.320680  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.326322  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.330012  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.333861  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.338250  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.343164  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.348389  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.354680  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.360773  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.383290  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.388359  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.393621  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.398626  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.403485  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.408748  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.413369  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.417849  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.422533  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.427408  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.432287  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.436964  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.441461  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.445969  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.450596  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.455601  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.460243  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.464938  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.469733  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.474385  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.479117  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.483848  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.488457  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.493858  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.499198  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.504480  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.510912  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.516605  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.526067  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.532057  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.541419  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.546946  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.553162  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.560978  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "2024-08-29 21:04:09.570393: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.33GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "W0000 00:00:1724987049.570488  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.596292  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.599168  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.601252  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.603293  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.605272  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.607141  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.609043  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.610950  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.612823  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.614711  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.616575  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.618436  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.620309  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.622191  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.624233  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.626232  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.628069  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.630076  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.632035  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.633946  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.636070  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original test data:\n",
      "Correctly classified: 32\n",
      "Incorrectly classified: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1724987049.637935  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.640083  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.642294  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.644094  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.646313  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.648230  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.650236  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.652166  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.654626  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.656650  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.659416  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.662150  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.665691  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.669378  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987049.673271  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    }
   ],
   "source": [
    "x_test_pred = np.argmax(classifier.predict(x_test), axis=1)\n",
    "\n",
    "nb_correct_pred = np.sum(x_test_pred == np.argmax(y_test, axis=1))\n",
    "\n",
    "print(\"Original test data:\")\n",
    "print(\"Correctly classified: {}\".format(nb_correct_pred))\n",
    "print(\"Incorrectly classified: {}\".format(len(x_test)-nb_correct_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on adversarial test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1724987057.680431  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.682408  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.684343  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.686438  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.688629  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.692472  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.694454  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.698853  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.700786  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.703016  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.704986  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.706942  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.708877  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.710865  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.712767  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.715017  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.719127  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.721600  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.724177  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.730788  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.734609  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.741493  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.745890  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.751145  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.839520  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.841532  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.843609  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.847034  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.849100  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.852036  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.853972  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.856000  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.858140  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.860292  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.862557  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.864888  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.871298  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.880722  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.885776  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.889286  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.898100  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.903122  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.907124  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.911441  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.928319  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.933987  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.938970  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.943812  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.948675  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.953918  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.958799  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.963763  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.968546  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.973470  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.978511  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.983617  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.988346  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.993609  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987057.998640  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.003556  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.009764  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.020320  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.026966  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.035382  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.045216  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.054381  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.064422  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.075935  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.092493  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.100462  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.106535  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.112193  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.117102  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.122202  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.127098  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.132013  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.137753  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.142928  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.146671  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.152898  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "2024-08-29 21:04:18.158461: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.21GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "W0000 00:00:1724987058.158541  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.166240  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.175421  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.187945  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.207625  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.219523  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.222696  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.225813  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.228915  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.231855  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.234952  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.237843  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.240800  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.243621  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.246450  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.249141  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.252165  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.255008  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.257702  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.261310  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.266155  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.269738  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.273866  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.279822  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.285041  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.290921  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.297443  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.318334  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.322116  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.325749  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.329248  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.332226  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.335449  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.338684  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.342033  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.345054  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.349099  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.351398  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.354275  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.357544  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.360972  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.364182  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.370471  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.374187  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.378774  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.383264  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.389481  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.393504  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.398749  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.404234  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.409414  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.415720  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.429207  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.434452  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.439485  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.444712  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.449612  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.454487  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.459571  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.464648  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.469499  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.474363  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.479321  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.484015  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.488932  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.493987  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.499054  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.504683  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.511816  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.518266  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.526890  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.533516  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.540460  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.549550  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.559308  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.571987  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.591733  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.597546  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.604328  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.610207  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.616441  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.622064  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.627448  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.633784  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.637773  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.644016  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.649778  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.656125  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.662176  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.668352  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.675943  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.683258  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.690463  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.697995  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.705316  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.714041  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.725066  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.735265  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.747733  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "2024-08-29 21:04:18.761190: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.21GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "W0000 00:00:1724987058.769558  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.785849  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.788995  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.792107  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.795248  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.798349  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.801413  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.804391  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.807483  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.810565  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.813460  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.816539  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.819691  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.823016  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.826485  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.831232  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.835131  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.838731  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.842626  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.846308  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.852970  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.859040  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.864053  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.870822  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.890757  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.894711  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.897970  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.902874  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.906769  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.910923  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.914319  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.918073  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.921679  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.924814  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.928479  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.932516  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.936275  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.939772  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.942735  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.947560  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.952183  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.956912  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.961678  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.967433  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.973337  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.979364  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.984900  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.992126  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987058.997037  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.002998  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.009928  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.014772  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.023027  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.049901  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.054895  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.060158  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.065425  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.070658  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.075731  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.080790  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.085712  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.090759  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.095977  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.101514  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.107196  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.113301  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.119532  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.127025  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.135716  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.143314  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.151163  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.158297  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.165080  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.177394  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.190404  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.211054  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.239861  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.247185  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.253660  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.260798  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.267835  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.274263  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.281262  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.288897  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.296099  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.307035  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.316773  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.328441  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.337882  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.344811  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.354546  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.363948  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.376662  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.387541  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.398683  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.414604  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.426187  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.443937  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.457576  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.471887  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.486933  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.502179  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.519714  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "2024-08-29 21:04:19.549767: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "W0000 00:00:1724987059.556838  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.560589  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.563808  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.567227  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.570444  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.573802  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.577196  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.580675  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.585567  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.590401  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.594576  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.599484  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.604501  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.609621  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.613848  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.619615  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.628105  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.632531  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.637350  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.643604  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.650273  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.658188  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.668632  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.687524  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.692088  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.696319  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.700841  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.705481  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.709426  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.714383  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.719026  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.726043  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.730484  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.736908  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.742151  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.749102  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.755996  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.761532  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.768340  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.775673  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.782430  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.788596  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.795839  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.803027  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.810846  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.816797  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.824148  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.831932  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.839347  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.856613  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.872675  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.878736  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.884633  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.891077  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.897830  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.904513  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.912048  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.922161  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.931988  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.941597  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.950262  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.960193  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.970515  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.983197  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987059.992476  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987060.009451  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987060.019180  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987060.028103  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987060.040174  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987060.060659  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987060.080903  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987060.126629  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987060.166792  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987060.649602  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987060.658823  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987060.667024  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987060.675919  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987060.687852  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987060.697764  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987060.711194  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987060.721293  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987060.733434  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987060.750570  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987060.772377  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987060.786406  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987060.800015  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987060.815362  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987060.837808  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987060.848751  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987060.862368  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987060.890942  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987060.916821  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987060.929250  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987060.945572  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987060.965116  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987060.988570  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.013873  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "2024-08-29 21:04:21.041628: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.55GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "W0000 00:00:1724987061.047098  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.056119  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.059603  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.066414  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.074066  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.080532  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.086928  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.092855  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.099246  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.105409  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.114628  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.124041  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.130709  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.140901  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.147818  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.155945  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.165988  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.170947  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.180450  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.207173  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.209330  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.211839  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.214269  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.217679  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.220593  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.223390  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.226844  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.229699  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.233106  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.236492  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.240133  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.243638  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.245690  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.250147  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.254070  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.258055  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.260915  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.267449  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.273186  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.279150  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.283801  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.406505  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.420055  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1724987061.434480  410359 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    }
   ],
   "source": [
    "attacker = FastGradientMethod(classifier, eps=0.1)\n",
    "x_test_adv = attacker.generate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial test data:\n",
      "Correctly classified: 4\n",
      "Incorrectly classified: 28\n"
     ]
    }
   ],
   "source": [
    "x_test_adv_pred = np.argmax(classifier.predict(x_test_adv), axis=1)\n",
    "nb_correct_adv_pred = np.sum(x_test_adv_pred == np.argmax(y_test, axis=1))\n",
    "\n",
    "print(\"Adversarial test data:\")\n",
    "print(\"Correctly classified: {}\".format(nb_correct_adv_pred))\n",
    "print(\"Incorrectly classified: {}\".format(len(x_test_adv)-nb_correct_adv_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model is not robust to adversarial examples generated with FGSM, with an eps = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "attacks = BasicIterativeMethod(classifier, eps=0.3, eps_step=0.01, max_iter=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.samples // train_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 197\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset saved in ./adversarial_batches/final_dataset.h5\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Directory to save batches\n",
    "save_dir = './adversarial_batches'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Create an HDF5 file to store the final dataset\n",
    "hdf5_file = h5py.File(os.path.join(save_dir, 'final_dataset.h5'), 'w')\n",
    "\n",
    "# Create datasets in the HDF5 file with appropriate shapes (initializing with empty data)\n",
    "x_train_shape = (train_generator.samples * 2, 150, 150, 3)  # Original + adversarial\n",
    "y_train_shape = (train_generator.samples * 2, 2)  # Adjust based on number of classes (2 in this case)\n",
    "\n",
    "x_train_dataset = hdf5_file.create_dataset(\"x_train_all\", x_train_shape, dtype='float32')\n",
    "y_train_dataset = hdf5_file.create_dataset(\"y_train_all\", y_train_shape, dtype='float32')\n",
    "\n",
    "# Process and store batches\n",
    "start_index = 0\n",
    "for i, (x_train, y_train) in enumerate(train_generator):\n",
    "    clear_output(wait=True)\n",
    "    print(f'Processing batch {i+1}')\n",
    "    \n",
    "    # Generate adversarial examples\n",
    "    x_train_adv = attacks.generate(x_train)\n",
    "    \n",
    "    # Ensure the shapes match for concatenation\n",
    "    if x_train_adv.shape == x_train.shape:\n",
    "        # Concatenate original and adversarial examples\n",
    "        combined_x_train = np.concatenate((x_train, x_train_adv), axis=0)\n",
    "        combined_y_train = np.concatenate((y_train, y_train), axis=0)\n",
    "        \n",
    "        # Write the current batch to HDF5 file\n",
    "        batch_size = combined_x_train.shape[0]\n",
    "        x_train_dataset[start_index:start_index+batch_size, ...] = combined_x_train\n",
    "        y_train_dataset[start_index:start_index+batch_size, ...] = combined_y_train\n",
    "        \n",
    "        # Update the index for the next batch\n",
    "        start_index += batch_size\n",
    "    \n",
    "    else:\n",
    "        print(f\"Shape mismatch: x_train shape = {x_train.shape}, x_train_adv shape = {x_train_adv.shape}\")\n",
    "        break\n",
    "    \n",
    "    # Stop after all batches have been processed\n",
    "    if i >= train_generator.samples // train_generator.batch_size:\n",
    "        break\n",
    "\n",
    "# Close the HDF5 file after writing all batches\n",
    "hdf5_file.close()\n",
    "\n",
    "print(f\"Final dataset saved in {os.path.join(save_dir, 'final_dataset.h5')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the HDF5 file for reading\n",
    "hdf5_file = h5py.File('./adversarial_batches/final_dataset.h5', 'r')\n",
    "\n",
    "# Load the datasets\n",
    "x_train_all = hdf5_file['x_train_all']\n",
    "y_train_all = hdf5_file['y_train_all']\n",
    "\n",
    "# Define a generator to yield batches of data\n",
    "def data_generator(batch_size):\n",
    "    num_samples = x_train_all.shape[0]\n",
    "    while True:\n",
    "        for start_idx in range(0, num_samples, batch_size):\n",
    "            end_idx = min(start_idx + batch_size, num_samples)\n",
    "            yield x_train_all[start_idx:end_idx], y_train_all[start_idx:end_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import ResNet50, VGG19, EfficientNetB4\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom layers on top of the base model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)  # Pool the feature maps from ResNet50\n",
    "x = Dense(512, activation='relu')(x)  # Add a fully connected layer\n",
    "x = Dense(2, activation='sigmoid')(x)  # Binary classification output layer\n",
    "\n",
    "# Define the final model\n",
    "model_robust = Model(inputs=base_model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,026</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m1,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m150\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv3 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv4 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv3 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv4 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv3 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv4 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │         \u001b[38;5;34m1,026\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,288,066</span> (77.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,288,066\u001b[0m (77.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">263,682</span> (1.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m263,682\u001b[0m (1.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,024,384</span> (76.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m20,024,384\u001b[0m (76.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_robust.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_robust.compile(\n",
    "        loss=\"categorical_crossentropy\", \n",
    "        optimizer=Adam(),\n",
    "    \tmetrics=[\"accuracy\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 22:22:15.256929: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1320', 36 bytes spill stores, 40 bytes spill loads\n",
      "\n",
      "2024-08-29 22:22:15.263515: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1320', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2024-08-29 22:22:15.276969: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1320', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 51ms/step - accuracy: 0.9104 - loss: 0.2212\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 22:22:36.971757: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_935', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-08-29 22:22:38.690985: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1320', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n",
      "2024-08-29 22:22:38.809375: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1320', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2024-08-29 22:22:40.545306: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng33{k2=2,k6=0,k13=2,k14=0,k22=1} for conv (f32[24,64,150,150]{3,2,1,0}, u8[0]{0}) custom-call(f32[24,64,150,150]{3,2,1,0}, f32[64,64,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2024-08-29 22:22:40.563628: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.050858961s\n",
      "Trying algorithm eng33{k2=2,k6=0,k13=2,k14=0,k22=1} for conv (f32[24,64,150,150]{3,2,1,0}, u8[0]{0}) custom-call(f32[24,64,150,150]{3,2,1,0}, f32[64,64,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 54ms/step - accuracy: 0.9774 - loss: 0.0819\n",
      "Epoch 3/10\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 57ms/step - accuracy: 0.9842 - loss: 0.0549\n",
      "Epoch 4/10\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 57ms/step - accuracy: 0.9873 - loss: 0.0427\n",
      "Epoch 5/10\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 55ms/step - accuracy: 0.9906 - loss: 0.0337\n",
      "Epoch 6/10\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 58ms/step - accuracy: 0.9922 - loss: 0.0261\n",
      "Epoch 7/10\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 58ms/step - accuracy: 0.9935 - loss: 0.0214\n",
      "Epoch 8/10\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 55ms/step - accuracy: 0.9942 - loss: 0.0178\n",
      "Epoch 9/10\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 58ms/step - accuracy: 0.9954 - loss: 0.0149\n",
      "Epoch 10/10\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 58ms/step - accuracy: 0.9961 - loss: 0.0156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f7a4c756e10>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "steps_per_epoch = x_train_all.shape[0] // batch_size\n",
    "\n",
    "model_robust.fit(data_generator(batch_size), \n",
    "          steps_per_epoch=steps_per_epoch, \n",
    "          epochs=10,\n",
    "          verbose=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_robust.save(\"vgg19_msu_categorical_robust.keras\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Evaluate the robust classifier's performance on the original test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_robust = tf.keras.models.load_model('vgg19_msu_categorical_robust.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_original = TensorFlowV2Classifier(model=model,\n",
    "                                    clip_values=(0, 1), \n",
    "                                    nb_classes=2, \n",
    "                                    input_shape=(150, 150, 3), \n",
    "                                    loss_object=loss_object,\n",
    "                                    optimizer = tf.keras.optimizers.Adam(),\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_robust = TensorFlowV2Classifier(model=model_robust,\n",
    "                                    clip_values=(0, 1), \n",
    "                                    nb_classes=2, \n",
    "                                    input_shape=(150, 150, 3), \n",
    "                                    loss_object=loss_object,\n",
    "                                    optimizer = tf.keras.optimizers.Adam(),\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original test data:\n",
      "Correctly classified: 32\n",
      "Incorrectly classified: 0\n"
     ]
    }
   ],
   "source": [
    "x_test_robust_pred = np.argmax(classifier_robust.predict(x_test), axis=1)\n",
    "nb_correct_robust_pred = np.sum(x_test_robust_pred == np.argmax(y_test, axis=1))\n",
    "\n",
    "print(\"Original test data:\")\n",
    "print(\"Correctly classified: {}\".format(nb_correct_robust_pred))\n",
    "print(\"Incorrectly classified: {}\".format(len(x_test)-nb_correct_robust_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The robust model can correctly classify all test data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Evaluate the robust classifier's performance on the adversarial test data (white-box):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "attacker_robust = FastGradientMethod(classifier_original, eps=0.5)\n",
    "x_test_adv_robust = attacker_robust.generate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial test data:\n",
      "Correctly classified: 27\n",
      "Incorrectly classified: 5\n"
     ]
    }
   ],
   "source": [
    "x_test_adv_robust_pred = np.argmax(classifier_robust.predict(x_test_adv_robust), axis=1)\n",
    "nb_correct_adv_robust_pred = np.sum(x_test_adv_robust_pred == np.argmax(y_test, axis=1))\n",
    "\n",
    "print(\"Adversarial test data:\")\n",
    "print(\"Correctly classified: {}\".format(nb_correct_adv_robust_pred))\n",
    "print(\"Incorrectly classified: {}\".format(len(x_test_adv_robust)-nb_correct_adv_robust_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model is now robust to adversarial examples (PGD-based attacks). Incorrectly classifying 5 samples compared to 23 from the original model. But with what epsilon size?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Compare the performance of the original and the robust classifier over a range of eps values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating adversarial examples for eps=0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating adversarial examples for eps=0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating adversarial examples for eps=0.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating adversarial examples for eps=0.03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating adversarial examples for eps=0.04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating adversarial examples for eps=0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating adversarial examples for eps=0.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating adversarial examples for eps=0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating adversarial examples for eps=0.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating adversarial examples for eps=0.4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating adversarial examples for eps=0.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating adversarial examples for eps=0.6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PGD - Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from art.attacks.evasion import ProjectedGradientDescent\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "# Define epsilon range for the PGD attack\n",
    "eps_range = [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "\n",
    "# Load the test data (x_test, y_test)\n",
    "x_test, y_test = next(test_generator)\n",
    "\n",
    "# Prepare lists to store accuracies for both classifiers\n",
    "original_accuracies = []\n",
    "robust_accuracies = []\n",
    "\n",
    "# Loop over the eps values in eps_range\n",
    "for eps in eps_range:\n",
    "    print(f\"Generating adversarial examples for eps={eps}\")\n",
    "    \n",
    "    # Generate adversarial examples using PGD\n",
    "    pgd_attack = ProjectedGradientDescent(estimator=classifier_original, eps=eps, eps_step=0.01, max_iter=40)\n",
    "    x_test_adv = pgd_attack.generate(x_test)\n",
    "    \n",
    "    # Evaluate original (non-robust) classifier on adversarial examples\n",
    "    _, original_acc = classifier_original._model.evaluate(x_test_adv, y_test, verbose=0)\n",
    "    original_accuracies.append(original_acc)\n",
    "    \n",
    "    # Evaluate robust classifier on the same adversarial examples\n",
    "    _, robust_acc = classifier_robust._model.evaluate(x_test_adv, y_test, verbose=0)\n",
    "    robust_accuracies.append(robust_acc)\n",
    "\n",
    "# Plot the results: Accuracy vs. Epsilon\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(eps_range, original_accuracies, label=\"Original Classifier\", marker='o')\n",
    "plt.plot(eps_range, robust_accuracies, label=\"Robust Classifier\", marker='x')\n",
    "plt.xlabel(\"Epsilon (Strength of PGD Attack)\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Original vs. Robust Classifier Accuracy under PGD Attack\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
